#!/usr/bin/env python3
"""
Beispiel f√ºr die Verwendung der Ollama RAG Integration
Demonstriert die Nutzung des nomic-embed-text-v1.5 Modells
"""

import asyncio

from src.rag_system import OllamaRAGSystem, RAGConfig, setup_ollama_models


async def main():
    print("ü¶ô Ollama RAG System Demo")
    print("=" * 50)

    # 1. Setup ben√∂tigte Modelle
    print("üîÑ Setting up required Ollama models...")
    success = await setup_ollama_models()
    if not success:
        print("‚ùå Failed to setup Ollama models. Please install Ollama first:")
        print("   curl -fsSL https://ollama.ai/install.sh | sh")
        return

    # 2. Konfiguration erstellen
    config = RAGConfig(
        llm_provider="ollama",
        ollama_model="nomic-embed-text-v1.5",  # Embedding-Modell
        ollama_chat_model="llama3.1:8b",  # Chat-Modell
        embedding_dimensions=768,
        temperature=0.1,
        max_tokens=1000,
    )

    # 3. RAG System initialisieren
    print("\nüöÄ Initializing Ollama RAG System...")
    rag_system = OllamaRAGSystem(config)

    # 4. Gesundheitscheck
    print("\nüîç Performing health check...")
    health = await rag_system.health_check()
    for key, value in health.items():
        status = "‚úÖ" if value else "‚ùå"
        print(f"   {status} {key}: {value}")

    # 5. Modell-Informationen anzeigen
    print("\nüìä Model Information:")
    model_info = await rag_system.get_model_info()
    for key, value in model_info.items():
        print(f"   {key}: {value}")

    # 6. Warte auf Indexierung (asynchron gestartet)
    print("\n‚è≥ Waiting for document indexing to complete...")
    await asyncio.sleep(5)  # Gib dem System Zeit zu indexieren

    # 7. Beispiel-Dokumente hinzuf√ºgen
    print("\nüìÑ Adding example documents...")
    example_docs = [
        """
        Python ist eine interpretierte, objektorientierte, h√∂here Programmiersprache mit dynamischer Semantik.
        Sie wurde 1991 von Guido van Rossum entwickelt und zeichnet sich durch ihre einfache, gut lesbare Syntax aus.
        Python unterst√ºtzt verschiedene Programmierparadigmen wie objektorientierte, imperative und funktionale Programmierung.
        """,
        """
        Machine Learning (ML) ist ein Teilbereich der K√ºnstlichen Intelligenz (KI), der es Computersystemen erm√∂glicht,
        automatisch zu lernen und sich zu verbessern, ohne explizit programmiert zu werden.
        ML-Algorithmen erstellen mathematische Modelle basierend auf Trainingsdaten, um Vorhersagen oder
        Entscheidungen zu treffen, ohne f√ºr spezifische Aufgaben programmiert zu werden.
        """,
        """
        Retrieval-Augmented Generation (RAG) ist eine Technik in der nat√ºrlichen Sprachverarbeitung,
        die die Vorteile von vortrainierten Sprachmodellen mit externen Wissensdatenbanken kombiniert.
        RAG-Systeme rufen relevante Informationen aus einer Datenbank ab und verwenden diese als Kontext
        f√ºr die Generierung pr√§ziser und faktisch korrekter Antworten.
        """,
    ]

    for i, doc in enumerate(example_docs):
        success = await rag_system.add_document(doc, {"source": f"example_{i + 1}"})
        if success:
            print(f"   ‚úÖ Added document {i + 1}")

    # 8. Beispiel-Queries ausf√ºhren
    print("\n‚ùì Example Queries:")
    print("-" * 30)

    queries = [
        "Was ist Python?",
        "Erkl√§re Machine Learning",
        "Wie funktioniert RAG?",
        "What are the main features of Python?",
        "Welche Programmierparadigmen unterst√ºtzt Python?",
    ]

    for query in queries:
        print(f"\nüîç Query: {query}")
        try:
            result = await rag_system.query(query, k=3)
            print(f"üìù Answer: {result['answer']}")
            print(f"‚è±Ô∏è  Processing time: {result['processing_time']:.2f}s")
            print(f"üîó Sources: {result['sources_count']}")
            print(f"ü§ñ Model: {result['model']}")
        except Exception as e:
            print(f"‚ùå Error: {e}")
        print("-" * 50)

    # 9. Performance-Test
    print("\n‚ö° Performance Test:")
    import time

    start_time = time.time()
    batch_queries = ["Was ist Python?"] * 5

    for i, query in enumerate(batch_queries):
        result = await rag_system.query(query, k=2)
        print(f"   Query {i + 1}: {result['processing_time']:.2f}s")

    total_time = time.time() - start_time
    avg_time = total_time / len(batch_queries)
    print(f"   Total time: {total_time:.2f}s")
    print(f"   Average time per query: {avg_time:.2f}s")

    # 10. Cleanup
    print("\nüßπ Cleaning up...")
    rag_system.close()
    print("‚úÖ Demo completed successfully!")


if __name__ == "__main__":
    asyncio.run(main())
